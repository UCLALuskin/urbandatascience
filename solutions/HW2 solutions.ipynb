{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a9341c15",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3dc7d80e158fc62b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "## Homework 2: Joins\n",
    "\n",
    "In this assignment, we'll use a variety of data sources to quantify the existence of food deserts in LA County. The assignment is *loosely* based on the food pantry example from class. It focuses on honing your skills in processing and joining data together, particularly spatially.\n",
    "\n",
    "A quick note: It's great to look at your variables, dataframes, etc. while you are exploring the data. But **please comment out those exploratory lines of code before submitting**. It makes it hard for us to find your solutions."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85c68b63-d851-438a-a0df-1e9ae6a90a26",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6adbb63f64f4b305",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "### Policy on ChatGPT and similar LLMs\n",
    "\n",
    "ChatGPT and similar tools can be useful in trying to figure out the syntax for a complex command, or to understand and fix an error. However, if you jump directly to ChatGPT for an answer, that means you aren't learning anything. \n",
    "\n",
    "Therefore, you may you use ChatGPT or a similar tool for this homework if you:\n",
    "- clearly acknowledge when and how you used the tool (e.g., \"I got a syntax error when trying to join the two dataframes, and asked ChatGPT for help\")\n",
    "- attempt the question on your own first, and try to fix any errors. Include your original attempts in your submission (you can comment out the lines that don't work)\n",
    "- briefly discuss what you learned from ChatGPT (e.g., \"I learned that function definitions need a colon (:) after the def statement.\"). Don't just uncritically accept ChatGPT's answer - learn from it!\n",
    "\n",
    "If you have any questions, talk to the instructor before you submit."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c77c6248",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-41843136c7998049",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "*Please help me grade* by observing the following:\n",
    " \n",
    "* Do not rename this notebook (that messes up the autograder)\n",
    "* Do not include large sections of output (that makes it hard to find your code). For example, use `df.head()` to show the first few rows, rather than printing an entire dataframe. The same goes for printing long strings."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90c0dd7b",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6a84245dac0a0a4e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Your homework repository includes a zipped csv file `snap.zip` of SNAP-authorized retailers, as of April 2025. [It was downloaded from USDA.](https://www.fns.usda.gov/snap/retailer-locator) To my knowledge, this is the most comprehensive list of grocery outlets in the US.\n",
    "\n",
    "Load it into a pandas dataframe called `snapDf`. Keep only the observations that are in Los Angeles County. \n",
    "\n",
    "*Hint:* pandas can read a `.zip` file directly...no need to unzip first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b3d0f0",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9c9db5adffa35ab6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "snapDf = 999  # replace with your DataFrame\n",
    "    \n",
    "### BEGIN SOLUTION\n",
    "\n",
    "import pandas as pd\n",
    "snapDf = pd.read_csv('snap.zip')\n",
    "snapDf = snapDf[snapDf.County=='LOS ANGELES']\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02caaaa3",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-305852f1c65f5253",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograding tests - do not edit\n",
    "print(snapDf.columns)\n",
    "print(snapDf.County.unique())\n",
    "print(len(snapDf))\n",
    "assert all(snapDf.columns == ['X', 'Y', 'Record_ID', 'Store_Name', 'Store_Street_Address', 'Additonal_Address',\n",
    "       'City', 'State', 'Zip_Code', 'Zip4', 'County', 'Store_Type', 'Latitude', 'Longitude', 'Incentive_Program',\n",
    "       'Grantee_Name', 'ObjectId'])\n",
    "assert len(snapDf)==8477"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "420c31f8",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d2ca8da07f678e6f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "If you look at the store names, many of the places that accept SNAP benefits are liquor stores and gas stations. These might have an important role where no other food is available, but are likely to have a limited range of food, particularly fresh produce. \n",
    "\n",
    "Most of these stores are labeled as `Convenience Store`. (That will also capture many other types of store, e.g. 7-11, but let's not worry about that for now.)\n",
    "\n",
    "Create a histogram of the `Store_Type` field. (pandas has a histogram function; you could also use the `histplot` function in the `seaborn` library.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61e612b5-f72c-4ee9-a5bd-686d045b03f6",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-112bb22e6c22eaea",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "\n",
    "# you could use the built in pandas hist() function too, but seaborn makes nicer plots\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "fig, ax = plt.subplots()\n",
    "sns.histplot(data=snapDf, x=\"Store_Type\", ax=ax)\n",
    "# optional, but makes the labels easier to read\n",
    "ax.tick_params(axis='x', labelrotation=90) \n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b31bcff8-c0a9-440f-bdd0-ffac711a39e8",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f6ee7415676417cf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You should see that Convenience Stores are the largest category.\n",
    "\n",
    "Let's keep them in the dataset for the moment, but label them.\n",
    "\n",
    "Create a new column, `convenience`, that is `True` if the store type is `Convenience Store` and `False` otherwise. Note that `True` and `False` should be boolean values, not the strings `\"True\"` and `\"False\"`. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7517184f",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-737e9a720cea57dd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "snapDf['convenience'] = snapDf.Store_Type=='Convenience Store'\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "679d34c7",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-8e1b371c073739f6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograding tests - do not edit\n",
    "print(snapDf.convenience.mean().round(2))\n",
    "print(snapDf.convenience.dtype)\n",
    "assert snapDf.convenience.mean().round(2) == 0.38\n",
    "assert snapDf.convenience.dtype=='bool'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6448cfdf",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6033d67150e950bf",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "If you look at the `City` field, there's some cleaning that needs to be done. You can see this by running the following cell:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4406ee12-0a2f-4e3d-8f25-e9a825fc31c4",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-80458fedb91aab5f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "snapDf.City.sort_values().unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf4884b-0c63-4023-84f1-245960b82845",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a5c20d2330367ec3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Replace the `City` field so that all the cities are in Title case. (Title case means the first letter of each word is capitalized, such as Los Angeles or North Hollywood.)\n",
    "\n",
    "*Hint:* The `title()` function works the same way as `upper()` and `lower()`.\n",
    "\n",
    "There is some other cleaning that we should do (e.g. there are sometimes two spaces between \"Los\" and \"Angeles\", but let's not worry about this here."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "978f9e12",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-48ebe7073a3f711b",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "snapDf.City = snapDf.City.str.title()\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4bb4b66a",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-a462b665a2ba1990",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograding tests - do not edit\n",
    "print(len(snapDf.City.unique()))\n",
    "assert len(snapDf.City.unique()) == 170\n",
    "assert 'Los Angeles' in snapDf.City.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0369f375",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-a3ad0abdd4125910",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "At this point, we might think about doing various analyses at the city level. But let's skip that, and move on to the ZIP code and census tract levels, and practice some joins.\n",
    "\n",
    "Let's bring in the [California EnviroScreen data](https://oehha.ca.gov/calenviroscreen/maps-data). This has both demographic and environmental justice-related data, and also the spatial boundaries of census tracts. We used it in class, so it will be in your GitHub course repository.\n",
    "\n",
    "Load the data in to a `geopandas` `GeoDataFrame` called `esGdf`, and restrict it to the tracts in LA county."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8722fd4f",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-f87e5fccf4b6108f",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "import geopandas as gpd\n",
    "esGdf = 999 # replace with your code\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "# grading note: you'll need to temporarily add the CES4 shapefile to the parent directory of the student repositories for this to work\n",
    "# i.e. in Assignments/\n",
    "esGdf = gpd.read_file('../../CalEnviroScreen/CES4 Final Shapefile.shp')\n",
    "esGdf = esGdf[esGdf.County=='Los Angeles']\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "319ba326",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-5ed4e65bf030fab1",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograding tests - do not edit\n",
    "print(len(esGdf))\n",
    "assert len(esGdf)==2343\n",
    "assert isinstance(esGdf, gpd.GeoDataFrame)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66effde4",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fed495a3b2b2f062",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "First, let's do a tabular (non-spatial) join to ZIP code.\n",
    "\n",
    "Create a new dataframe called `zipcodes` with one row for each ZIP code, that includes the following columns:\n",
    "* `n_SNAP`: the number of SNAP outlets\n",
    "* `es_percentile`: the mean EnviroScreen percentile (`CIscoreP`) for census tracts in that ZIP code \n",
    "\n",
    "No spatial join is needed here - ZIP is already a column in your datasets.\n",
    "\n",
    "(In practice, we might want to weight census tracts by area or population, but don't worry about that here.)\n",
    "\n",
    "*Hints*:\n",
    "- `groupby` is your friend here\n",
    "- I recommend creating two temporary dataframes (or Series) at the ZIP-code level with the number of SNAP outlets and the mean EnviroScreen score\n",
    "- If you get an error that `Series object has no attribute 'join'`, you can convert that Series to a DataFrame: `pd.DataFrame(your_series_name)` \n",
    "- Then, you can join them all together\n",
    "- You might need to rename the columns\n",
    "- Remember to include all ZIP codes, including ones without a SNAP outlet, and replace NaNs with zeros if appropriate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12d4cdfd",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-69fdaeb9e6fde589",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "zipcodes = 999\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "# create tmp dataframes\n",
    "tmp1 = snapDf.groupby('Zip_Code').size()\n",
    "tmp1.name = 'n_SNAP'\n",
    "tmp2 = esGdf.groupby('ZIP').CIscoreP.mean()\n",
    "tmp2.name = 'es_percentile'\n",
    "\n",
    "# join them together. Note that the indexes should already be the ZIP code\n",
    "# do a left join from the EnviroScreen data to keep all the ZIP codes\n",
    "# we could also have done an outer join in any order\n",
    "zipcodes = pd.DataFrame(tmp2).join(tmp1)\n",
    "\n",
    "# replace missing data\n",
    "zipcodes.fillna({'n_SNAP':0}, inplace=True)\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4090c413",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-a025aae73108a6ad",
     "locked": true,
     "points": 2,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograding tests - do not edit\n",
    "\n",
    "print(len(zipcodes))\n",
    "print(zipcodes.mean())\n",
    "\n",
    "assert len(zipcodes) == 282\n",
    "assert zipcodes.es_percentile.mean().round(1) == 26.7\n",
    "assert zipcodes.n_SNAP.mean().round(1) == 29.9"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c7d71fc",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5888194e2f4afc11",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now let's do a spatial join. \n",
    "\n",
    "`esGdf` already has a `geometry` column and is a GeoDataFrame, but `snapDf` is a regular pandas DataFrame.\n",
    "\n",
    "Use the `Latitude` and `Longitude` columns to add a point geometry field to `snapDf`, and turn it into a `GeoDataFrame` called `snapGdf`. Remember to specify the projection!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a3ed4df",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9987c034d487a7f6",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "snapGdf = 999 # replace 999 with your solution\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "snapGdf = gpd.GeoDataFrame(\n",
    "    snapDf, geometry=gpd.points_from_xy(snapDf.Longitude, snapDf.Latitude, crs='EPSG:4326'))\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31a32e07",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-4f619f3ad43dba06",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograding tests - do not edit\n",
    "import numpy as np\n",
    "print(snapGdf.geometry.x.min())\n",
    "print(snapGdf.geometry.y.max())\n",
    "print(snapGdf.crs)\n",
    "assert isinstance(snapGdf, gpd.GeoDataFrame)\n",
    "assert np.round(snapGdf.geometry.x.min(), 2) == -118.87\n",
    "assert np.round(snapGdf.geometry.y.max(), 2) == 34.80\n",
    "assert '4326' in snapGdf.crs.to_string()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "955036ef",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3f672bf7068df0ca",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now, let's join the two GeoDataFrames together. The aim: count the number of SNAP outlets and obtain the proportion of them that are convenience stores, per census tract.\n",
    "\n",
    "There are several ways to do it. My suggestion is as follows:\n",
    "1. Add the `tract` column to `snapGdf` using a spatial join\n",
    "2. Aggregate `snapGdf` by the new `tract` column using `groupby()`, to get your desired aggregates by tract\n",
    "3. Join those counts to `esGdf`\n",
    "\n",
    "Let's do these one step at a time. First, add the `tract` column to `snapGdf`. I suggest you use the `gpd.sjoin()` function and a left join. Call the new GeoDataFrame `snapGdf2`.\n",
    "\n",
    "*Hint:* You might need to reproject!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6846011d",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5e76ac9ba8d18da8",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "snapGdf2 = 999 # replace 999 with your code\n",
    "\n",
    "#### BEGIN SOLUTION\n",
    "snapGdf2 = gpd.sjoin(snapGdf, esGdf.to_crs('EPSG:4326'), how=\"left\", predicate='intersects')\n",
    "# if you project to 3310, you get a slightly different answer\n",
    "#snapGdf2 = gpd.sjoin(snapGdf.to_crs('EPSG:3310'), esGdf,  how=\"left\", predicate='intersects')\n",
    "\n",
    "#### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6ff7f51c",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-9df174d78f540fa0",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograding tests - do not edit\n",
    "print(len(snapGdf2))\n",
    "\n",
    "assert len(snapGdf2) in [8502, 8501] # the answer depends on the projection\n",
    "assert 'Tract' in snapGdf2.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "df26d5a9",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-60b82c2155a719e8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "That should have been a 1:many join, not the 1:1 join that you might have been expecting. (You ended up with more rows than you started with). Think about what might have caused this! \n",
    "\n",
    "We didn't cover in class how to drop the duplicates, but the block of code below should fix it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce65e1af",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-70e591fd94f9751c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "print('{} rows in snapGdf'.format(len(snapGdf)))\n",
    "print('{} rows in snapGdf2 (after join)'.format(len(snapGdf2)))\n",
    "\n",
    "# you can also see that the ObjectId column (which identifies the SNAP providers) \n",
    "# is unique before the join, but not after\n",
    "print(snapGdf.ObjectId.is_unique)  # is there one row per SNAP outlet before the join?\n",
    "print(snapGdf2.ObjectId.is_unique) # is there one row per SNAP outlet after the join?\n",
    "\n",
    "# drop the duplicates by just taking the first ObjectId that joins to each tract\n",
    "# https://pandas.pydata.org/docs/reference/api/pandas.DataFrame.drop_duplicates.html\n",
    "snapGdf2.drop_duplicates(subset='ObjectId', keep='first', inplace=True)\n",
    "print('{} rows in snapGdf2 (after dropping duplicates)'.format(len(snapGdf2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f905a6",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e7a71e649a4ce0f2",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now, aggregate snapGdf2 by the new `tract` column to create a dataframe with (i) the number of all SNAP outlets in that tract, and (ii) the proportion of SNAP outlets that are convenience stores in that tract. \n",
    "\n",
    "Call those columns `n_snap` and `frc_convenience`, and the dataframe `tract_counts`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ae5f4b5",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-d67798f8deff3de7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "tract_counts = 999 # your code here\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "# here, we get the mean of `convenience` and the number\n",
    "# we could also have aggregated the count and the mean separately, and done another join\n",
    "tract_counts = snapGdf2.groupby('Tract').convenience.agg(['count', 'mean'])\n",
    "tract_counts.rename(columns={'count':'n_snap', 'mean':'frc_convenience'}, inplace=True)\n",
    "### END SOLUTION\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44f24aac",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-33e9bdc1d457a990",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograding tests - do not edit\n",
    "print(tract_counts.mean())\n",
    "assert np.round(tract_counts.n_snap.mean(),1)==4.3 \n",
    "assert np.round(tract_counts.frc_convenience.mean(),2) in [0.42, 42.96]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ea748f8",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9d9459ea0c856988",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Final step in the join process! Let's join `tract_counts` back to `esGdf` to create a new geodataframe called `joinedGdf`. \n",
    "\n",
    "This should be a left join (so you don't leave out any census tracts) on the `Tract` column.\n",
    "\n",
    "Remember to fill in any missing data for `n_snap` with zeros. (Should you also fill in the NaNs for `frc_convenience`? Probably not - if there aren't any SNAP outlets, we actually don't have any information on the fraction, and so it's more appropriate to leave it as NaN."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba1d2dc6",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9c26e2d30dccf9a3",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "joinedGdf = 999 # your answer here\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "joinedGdf = esGdf.set_index('Tract').join(tract_counts, how='left')\n",
    "joinedGdf.fillna({'n_snap':0} , inplace=True)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9440cba7",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-97e95ed64aa5aeed",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograding tests - do not edit\n",
    "\n",
    "print(len(joinedGdf))\n",
    "print(joinedGdf.n_snap.sum(), joinedGdf.frc_convenience.sum())\n",
    "assert len(joinedGdf) == len(esGdf)\n",
    "assert tract_counts.n_snap.sum() == joinedGdf.n_snap.sum()\n",
    "assert joinedGdf.n_snap.count() == len(joinedGdf)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dafc156a",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2072e2bd2aef1387",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now plot the `n_snap` and `frc_convenience` columns (2 separate maps). Use the examples from class. At a minimum, your maps should have:\n",
    "* a basemap (e.g. from contextily)\n",
    "* a legend or colorbar\n",
    "* a title\n",
    "\n",
    "If you can figure it out, you might want to drop Catalina Island to focus on mainland LA County. (Hint: the `ax.set_ylim()` function is useful here.)\n",
    "\n",
    "Your code will be shorter, more elegant and easier to understand if you use a loop! But it's fine if you don't do it that way."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e9f18161",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-a94ea91d437aa315",
     "locked": false,
     "points": 3,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "import contextily as ctx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "# since we are doing 2 plots that are pretty much identical, we can use a loop!\n",
    "# this creates axes as a list of axes objects\n",
    "for colname in ['n_snap','frc_convenience']:\n",
    "    fig, ax = plt.subplots(figsize=(10,5))\n",
    "    joinedGdf.to_crs('EPSG:3857').plot(colname, cmap='viridis', legend=True, ax = ax, alpha=0.4)\n",
    "\n",
    "    # drop Catalina\n",
    "    ax.set_ylim([3.98e6, 4.14e6])\n",
    "    ctx.add_basemap(ax, zoom=12, source=ctx.providers.OpenStreetMap.Mapnik)\n",
    "\n",
    "    # and we really don't need the axis ticks and labels, so we set them to an empty list\n",
    "    ax.set_xticks([])\n",
    "    ax.set_yticks([])\n",
    "\n",
    "    # here, we can do stuff that is a bit different across plots\n",
    "    if colname == 'n_snap':\n",
    "        titletext = 'Number of SNAP outlets' \n",
    "    else:\n",
    "        titletext = 'Fraction of convenience stores' \n",
    "        \n",
    "    ax.set_title(titletext, fontsize=12)\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d2480c3",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-758f0b04ca485f4c",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Reflect on this assignment. What did you find most challenging? What problems did you encounter? How might you have gone about it differently the next time? (Write a few bullet points in a markdown cell.)\n",
    "\n",
    "To help me calibrate future assignments, please also indicate about how long it took you to complete."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea7fc17d-21dd-4ae0-8081-8c99eaff55ec",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "33dcc1c4",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e66877e145e6c79b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Challenge Problem\n",
    "Remember, you need to do at least two of these challenge problems this quarter.\n",
    "\n",
    "We mapped the number of grocery stores, but didn't say anything directly about food deserts. In the challenge, take this analysis further. My suggestion:\n",
    "* Normalize your number of outlets (e.g. by population) and plot these data\n",
    "* Plot the normalized number of outlets (both including and excluding convenience stores) against race, income, and other variables from EnviroScreen\n",
    "* Think about boundary issues created by the artefacts of census geography. Create a measure of the number of outlets within (say) 2km of a census tract boundary, even if they do not intersect that tract\n",
    "* Briefly write a few sentences that intepret your results\n",
    "\n",
    "If you want to go further, please do!\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a9f5568f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
