{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53fce03f",
   "metadata": {},
   "source": [
    "## Module 2 Class activities\n",
    "This notebook is a starting point for the exercises and activities that we'll do in class.\n",
    "\n",
    "Before you attempt any of these activities, make sure to watch the video lectures for this module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c092609b",
   "metadata": {},
   "source": [
    "### Scraping permit data\n",
    "Here's the code that we saw in the video lecture that queries the City of Seattle permit website, gets a dataframe of permits (including the URL), and then digs down further into that permit-specific URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89222500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the permit data from the API\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://data.seattle.gov/resource/ht3q-kdvx.json' # copied and pasted from the webpage\n",
    "r = requests.get(url)\n",
    "df = pd.DataFrame(json.loads(r.text))\n",
    "\n",
    "df = df.head(20) # get the first 5 rows, so we don't overload the city's website.\n",
    "\n",
    "# get an example link\n",
    "permiturl = df.loc[8,'link']['url']\n",
    "print(permiturl)\n",
    "\n",
    "# request that page and get the soup object\n",
    "r = requests.get(permiturl)\n",
    "soup = BeautifulSoup(r.text)\n",
    "#print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59022053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then we wrote this code to extract the project description \n",
    "links = soup.find_all('td')\n",
    "for link in links:\n",
    "    if 'Project Description' in link.text: \n",
    "        sublinks = link.find_all('td')\n",
    "        description = sublinks[1].text\n",
    "        # once we find a description, we exit\n",
    "        break\n",
    "    \n",
    "print(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6d730d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> If you look at the example, there may be a section giving information on the number of curb cuts. Extract that to a variable and print it.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab6670e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hints\n",
    "# Not all of the records have the curb cut field. You can see an example here:\n",
    "# https://services.seattle.gov/portal/customize/LinkToRecord.aspx?altId=3001776-LU\n",
    "\n",
    "    # If you look at that webpage, you'll see that the text \"Number of Curb Cuts for This Permit: \"\n",
    "# is within \"span\" tags\n",
    "curbcuttext = soup.find(\"span\", string=\"Number of Curb Cuts for This Permit: \")\n",
    "\n",
    "# So to get the number of curb cuts (which is the next piece of text), \n",
    "# you can ask for the NEXT tag using find_next()\n",
    "#n_curbcuts = curbcuttext.find_next()\n",
    "\n",
    "# you'll need to add an if statement to deal with the case when this text does not exist\n",
    "    \n",
    "# your code here\n",
    "# all I did was extract the text, and add the if statement\n",
    "if curbcuttext is None:\n",
    "    n_curbcuts = np.nan\n",
    "else:\n",
    "    n_curbcuts = int(curbcuttext.find_next().text)\n",
    "print(n_curbcuts)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041fefc9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> Now turn that into a function that you can apply to each row of your dataframe. Add a new column, <strong>n_curbcuts</strong>, to your dataframe.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af29ac85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "# I just copied and pasted the code above\n",
    "# and indented it into a function\n",
    "def get_curbcuts(urldict):\n",
    "    permiturl = urldict['url']\n",
    "    \n",
    "    r = requests.get(permiturl)\n",
    "    soup = BeautifulSoup(r.text)\n",
    "    \n",
    "    curbcuttext = soup.find(\"span\", string=\"Number of Curb Cuts for This Permit: \")\n",
    "    \n",
    "    if curbcuttext is None:\n",
    "        n_curbcuts = np.nan\n",
    "    else:\n",
    "        n_curbcuts = int(curbcuttext.find_next().text)\n",
    "\n",
    "    print(n_curbcuts)\n",
    "    return(n_curbcuts)\n",
    "    \n",
    "\n",
    "get_curbcuts(df.loc[8,'link'])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
