{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "8521be31",
   "metadata": {
    "editable": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-efc8e2cd6c423ad3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "## Homework 4: Cluster analysis\n",
    "\n",
    "In this assignment, we'll do cluster analysis of transit agencies. Our goal: identify whether there are groups of \"more similar\" agencies. This type of analysis might help us identify a peer group for a particular agency, against which it can be benchmarked.\n",
    "\n",
    "We'll use the [2023 National Transit Database](https://www.transit.dot.gov/ntd), which compiles the data that each transit agencies must report to the Federal Transit Administration.\n",
    "\n",
    "The relevant spreadsheets are in your repository. "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c32fd724",
   "metadata": {
    "editable": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-22802eecdb3ed8cc",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Please help me grade by observing the following:\n",
    " \n",
    "* Do not rename this notebook (that messes up the autograder)\n",
    "* Do not include large sections of output (that makes it hard to find your code). For example, use `df.head()` to show the first few rows, rather than printing an entire dataframe. The same goes for printing long strings.\n",
    "* Follow the same guidelines for ChatGPT / LLM usage as in previous assignments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81c2d6b3",
   "metadata": {
    "editable": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-5cb8d66382de344e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "source": [
    "Load in `2023 Agency Information_0.xlsx.xlsx` to a `pandas` DataFrame called `agency_info`.\n",
    "\n",
    "You can use the `pd.read_excel()` command, which works in the same way as `pd.read_csv()`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4457415",
   "metadata": {
    "editable": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9d1ff6bbc326c6c7",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    },
    "slideshow": {
     "slide_type": "slide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "agency_info = 999 # replace with your code\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "import pandas as pd\n",
    "fn = '2023 Agency Information_0.xlsx'\n",
    "agency_info = pd.read_excel(fn)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8dc5425b",
   "metadata": {
    "editable": true,
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-bdf98bf21a1a7205",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Autograder tests - do not edit\n",
    "\n",
    "print(len(agency_info))\n",
    "print(agency_info.columns)\n",
    "print(len(agency_info.columns))\n",
    "\n",
    "assert len(agency_info)==2899\n",
    "assert 'NTD ID' in agency_info.columns\n",
    "assert len(agency_info.columns)==43"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b30637f1-461e-49c8-a78b-ef84b50f4df1",
   "metadata": {
    "editable": true,
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-6ec260b72e883fd5",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    },
    "slideshow": {
     "slide_type": "subslide"
    },
    "tags": []
   },
   "source": [
    "There are two duplicated NTD ids - it's not clear why. You will need to drop them to avoid double counting in subsequent steps. I suggest you do it like this."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1923e3dd-a4d0-4cb8-b1c0-df79ab109410",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9d40449a599cf8d3",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "agency_info = agency_info.drop_duplicates(subset='NTD ID') # will keep only the first, where there are duplicate ids\n",
    "assert agency_info['NTD ID'].is_unique # check it worked"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6627fa7a",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-370cbc18bb4fb2a8",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Load in the `service_bymode_2023.csv` file to a dataframe called `service` in the same way.\n",
    "\n",
    "Most of the columns should be self explanatory, but you may need to refer to the [data dictionary](https://www.transit.dot.gov/ntd/data-product/2023-ntd-database-file-dictionary) or [glossary](https://www.transit.dot.gov/ntd/national-transit-database-ntd-glossary).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6404e77c",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3c2b767eb149a9bb",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "service = 999 # replace with your code\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "fn = 'service_bymode_2023.csv'\n",
    "service = pd.read_csv(fn)\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c3f8a42",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-3ca0f3c317f75d70",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests - do not edit\n",
    "\n",
    "print(len(service))\n",
    "print(len(service.columns))\n",
    "\n",
    "assert len(service)==3681\n",
    "assert '_5_digit_ntd_id' in service.columns\n",
    "assert len(service.columns)==46"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "315c9510-793c-45c2-8614-0a72527fa3e6",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-98cf1096178c0e3a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You probably notice that there are many more rows in the `service` dataframe. If you look at the first few rows, you can see that each agency has different rows for:\n",
    "* different modes (e.g. `MB` is motorbus)\n",
    "* different types of service (directly operated is `DR` and contracted / purchased is `PT`)\n",
    "\n",
    "If we do a join with `agency_info`, we'll end up with a 1:many join. That's not as useful if we want to cluster transit agencies.\n",
    "\n",
    "So let's aggregate the `service` data first. Create a new dataframe, `service_agg`, that:\n",
    "1. Keeps only the rows for Buses/Trolleybuses/Commuter Buses/Bus Rapid Transit (`mode` is `MB`, `TB`, `CB` or `RB`, so we are comparing like with like). Hint: the `in` operator is useful here.\n",
    "2. Groups by the agency (NTD ID, called `_5_digit_ntd_id`) and sums these columns:\n",
    "\n",
    "* Unlinked Passenger Trips (`sum_unlinked_passenger_trips_upt`)\n",
    "* Passenger Miles (`sum_passenger_miles`)\n",
    "* Revenue Miles (`sum_actual_vehicles_passenger_car_revenue_miles`), i.e., how distance traveled while in revenue service (vehicles/cars here refers to buses/train cars, not automobiles)\n",
    "* Deadhead Miles (`sum_actual_vehicles_passenger_deadhead_miles`)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe665c11",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-0f3828cd3561b6fd",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "service_agg = 999 # replace with your code\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "service = service[service['mode'].isin(['MB','CB','TB','RB'])]\n",
    "service_agg = service.groupby('_5_digit_ntd_id')[['sum_unlinked_passenger_trips_upt', \n",
    "                                         'sum_passenger_miles', 'sum_actual_vehicles_passenger_car_revenue_miles',\n",
    "                                         'sum_actual_vehicles_passenger_deadhead_miles']].sum()\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ebbc545b",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-0a13773f89540dd6",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests - do not edit\n",
    "\n",
    "print(len(service_agg))\n",
    "print(service_agg.sum_unlinked_passenger_trips_upt.sum())\n",
    "\n",
    "assert(len(service_agg)==1204)\n",
    "assert service_agg.index.name=='_5_digit_ntd_id'\n",
    "assert service_agg.sum_unlinked_passenger_trips_upt.sum() == 3475162210"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47914980",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-58dd43b7922e769b",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Now, join your `service_agg` dataframe to your `agency_info` dataframe. Call the new dataframe `transit`. \n",
    "\n",
    "You should note that the `agency_info` has more rows that `service_agg`, because some small agencies aren't required to report service information. Drop those - you can do either an inner join, or a left join to `service_agg`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c1d703c",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-755b9b132e3ebb63",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "transit = 999  # replace with your code\n",
    "### BEGIN SOLUTION\n",
    "transit = service_agg.join(agency_info.set_index('NTD ID'))\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4da28145",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-5dcf1b144440f7a9",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests - do not edit\n",
    "\n",
    "print(len(transit))\n",
    "print(transit.sum_unlinked_passenger_trips_upt.sum())\n",
    "print(transit.Population.sum())\n",
    "\n",
    "assert len(transit)==1204\n",
    "assert transit.sum_unlinked_passenger_trips_upt.sum() == 3475162210\n",
    "assert transit.Population.sum() == 2109627865\n",
    "#why isn't this the same sum as above?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "caf21ac4",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-841eb3f66ed45b8e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "The final data preparation step is to standardize the variables. Some of them are strings (use `transit.info()` to take a look). But let's standardize the numeric ones that we might want to use to cluster.\n",
    "\n",
    "Create a data frame, `df_to_cluster`, with the following standardized variables: \n",
    "* sum_unlinked_passenger_trips_upt\n",
    "* sum_passenger_miles\n",
    "* sum_actual_vehicles_passenger_car_revenue_miles \n",
    "* sum_actual_vehicles_passenger_deadhead_miles \n",
    "* Population\n",
    "* Density\n",
    "* Total VOMS (vehicles operated in maximum service)\n",
    "\n",
    "(See Lecture 14 on neural networks for how to standardize.)\n",
    "\n",
    "It should still be indexed by NTD ID (`_5_digit_ntd_id`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59bda177",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-81e7692420bfc71c",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "\n",
    "# your code here\n",
    "df_to_cluster = 999 \n",
    "\n",
    "### BEGIN SOLUTION\n",
    "cols = ['sum_unlinked_passenger_trips_upt','sum_passenger_miles', \n",
    "        'sum_actual_vehicles_passenger_car_revenue_miles',\n",
    "        'sum_actual_vehicles_passenger_deadhead_miles', \n",
    "        'Population','Density', 'Total VOMS']\n",
    "scaler = preprocessing.StandardScaler().fit(transit[cols])\n",
    "\n",
    "# convert to DataFrame and specify the column names and index\n",
    "df_to_cluster = pd.DataFrame(scaler.transform(transit[cols]), \n",
    "                         columns=cols, index=transit.index)\n",
    "\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d772ccf2",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-9ab71dec9556a50e",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests - do not edit\n",
    "print(len(df_to_cluster))\n",
    "print(df_to_cluster.Population.mean())\n",
    "print(df_to_cluster.sum_unlinked_passenger_trips_upt.mean())\n",
    "print(len(df_to_cluster.columns))\n",
    "\n",
    "assert len(df_to_cluster)==1204\n",
    "assert df_to_cluster.Population.mean().round(5)==0\n",
    "assert df_to_cluster.sum_unlinked_passenger_trips_upt.mean().round(5)==0\n",
    "assert len(df_to_cluster.columns) == 7"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f72fff1",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-2ca67b40aeb5676f",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Let's start with 5 clusters. Use the `KMeans` algorithm to assign each observation to a cluster.\n",
    "\n",
    "Add the cluster number (id) to a new column in your original `df_to_cluster` dataframe. Call the new column `cluster_id`.\n",
    "\n",
    "*Hint:* Drop the Null values before trying to cluster. And see lecture 15 (clustering) for an example."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab0c3ed0",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-9287b9deadcb782d",
     "locked": false,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "from sklearn.cluster import KMeans\n",
    "\n",
    "# your code here\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "df_to_cluster.dropna(inplace=True)\n",
    "kmeans = KMeans(n_clusters=5).fit(df_to_cluster)\n",
    "df_to_cluster['cluster_id'] = kmeans.labels_\n",
    "df_to_cluster.groupby('cluster_id').size()\n",
    "### END SOLUTION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a270a41f",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-f304596d7719f05a",
     "locked": true,
     "points": 1,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# Autograder tests - do not edit\n",
    "print(df_to_cluster.groupby('cluster_id').size())\n",
    "\n",
    "assert len(df_to_cluster.groupby('cluster_id').size())==5\n",
    "assert df_to_cluster.groupby('cluster_id').size().min()==1\n",
    "cmax = df_to_cluster.groupby('cluster_id').size().max()\n",
    "assert cmax>700 and cmax<710"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6163116",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-870146bca6702e7a",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "You should have one cluster that is a single transit agency. And another that is just 2 agencies.\n",
    "\n",
    "What's the name of the agency that's in the cluster of one? (*Hint*: you can get its id from `df_to_cluster`, and its name from `transit`, your original dataframe.)\n",
    "Comment on whether this seems reasonable."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accb8d72",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-9fdc88d79e0cfcc6",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "36e12277",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-3b541129eae9eb71",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Create a radar plot that shows how your clusters relate to your 7 variables. Here's the function to create a radar plot that we used in the lecture.\n",
    "\n",
    "*Hint*: You'll need to drop the `cluster_id` column first."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95eabd8b",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-e2442474bd8062de",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# code from https://matplotlib.org/stable/gallery/specialty_plots/radar_chart.html\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle, RegularPolygon\n",
    "from matplotlib.path import Path\n",
    "from matplotlib.projections.polar import PolarAxes\n",
    "from matplotlib.projections import register_projection\n",
    "from matplotlib.spines import Spine\n",
    "from matplotlib.transforms import Affine2D\n",
    "\n",
    "\n",
    "def radar_factory(num_vars, frame='circle'):\n",
    "    \"\"\"\n",
    "    Create a radar chart with `num_vars` axes.\n",
    "\n",
    "    This function creates a RadarAxes projection and registers it.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_vars : int\n",
    "        Number of variables for radar chart.\n",
    "    frame : {'circle', 'polygon'}\n",
    "        Shape of frame surrounding axes.\n",
    "\n",
    "    \"\"\"\n",
    "    # calculate evenly-spaced axis angles\n",
    "    theta = np.linspace(0, 2*np.pi, num_vars, endpoint=False)\n",
    "\n",
    "    class RadarAxes(PolarAxes):\n",
    "\n",
    "        name = 'radar'\n",
    "        # use 1 line segment to connect specified points\n",
    "        RESOLUTION = 1\n",
    "\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            super().__init__(*args, **kwargs)\n",
    "            # rotate plot such that the first axis is at the top\n",
    "            self.set_theta_zero_location('N')\n",
    "\n",
    "        def fill(self, *args, closed=True, **kwargs):\n",
    "            \"\"\"Override fill so that line is closed by default\"\"\"\n",
    "            return super().fill(closed=closed, *args, **kwargs)\n",
    "\n",
    "        def plot(self, *args, **kwargs):\n",
    "            \"\"\"Override plot so that line is closed by default\"\"\"\n",
    "            lines = super().plot(*args, **kwargs)\n",
    "            for line in lines:\n",
    "                self._close_line(line)\n",
    "\n",
    "        def _close_line(self, line):\n",
    "            x, y = line.get_data()\n",
    "            # FIXME: markers at x[0], y[0] get doubled-up\n",
    "            if x[0] != x[-1]:\n",
    "                x = np.append(x, x[0])\n",
    "                y = np.append(y, y[0])\n",
    "                line.set_data(x, y)\n",
    "\n",
    "        def set_varlabels(self, labels):\n",
    "            self.set_thetagrids(np.degrees(theta), labels)\n",
    "\n",
    "        def _gen_axes_patch(self):\n",
    "            # The Axes patch must be centered at (0.5, 0.5) and of radius 0.5\n",
    "            # in axes coordinates.\n",
    "            if frame == 'circle':\n",
    "                return Circle((0.5, 0.5), 0.5)\n",
    "            elif frame == 'polygon':\n",
    "                return RegularPolygon((0.5, 0.5), num_vars,\n",
    "                                      radius=.5, edgecolor=\"k\")\n",
    "            else:\n",
    "                raise ValueError(\"Unknown value for 'frame': %s\" % frame)\n",
    "\n",
    "        def _gen_axes_spines(self):\n",
    "            if frame == 'circle':\n",
    "                return super()._gen_axes_spines()\n",
    "            elif frame == 'polygon':\n",
    "                # spine_type must be 'left'/'right'/'top'/'bottom'/'circle'.\n",
    "                spine = Spine(axes=self,\n",
    "                              spine_type='circle',\n",
    "                              path=Path.unit_regular_polygon(num_vars))\n",
    "                # unit_regular_polygon gives a polygon of radius 1 centered at\n",
    "                # (0, 0) but we want a polygon of radius 0.5 centered at (0.5,\n",
    "                # 0.5) in axes coordinates.\n",
    "                spine.set_transform(Affine2D().scale(.5).translate(.5, .5)\n",
    "                                    + self.transAxes)\n",
    "                return {'polar': spine}\n",
    "            else:\n",
    "                raise ValueError(\"Unknown value for 'frame': %s\" % frame)\n",
    "\n",
    "    register_projection(RadarAxes)\n",
    "    return theta\n",
    "\n",
    "def radar_plot(kmeans, df_scaled):\n",
    "    N  = kmeans.cluster_centers_.shape[1]  # number of columns / variables\n",
    "    k = kmeans.n_clusters\n",
    "    theta = radar_factory(N, frame='polygon')\n",
    "    data = kmeans.cluster_centers_.T\n",
    "    spoke_labels = [col for col in df_scaled.columns if col!='cluster_id']\n",
    "    fig, ax = plt.subplots(figsize=(9, 9),\n",
    "                                subplot_kw=dict(projection='radar'))\n",
    "    fig.subplots_adjust(wspace=0.25, hspace=0.20, top=0.85, bottom=0.05)\n",
    "\n",
    "    ax.plot(theta, data) #, color=color)\n",
    "    ax.set_varlabels(spoke_labels)\n",
    "\n",
    "    # add legend relative to top-left plot\n",
    "    labels = ['Cluster {}'.format(kk) for kk in range(k)]\n",
    "    ax.legend(labels, loc=(0.9, .95),\n",
    "                                labelspacing=0.1, fontsize='small')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea20e7fb",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-fface58e302ba59b",
     "locked": false,
     "points": 1,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here\n",
    "\n",
    "### BEGIN SOLUTION\n",
    "radar_plot(kmeans, df_to_cluster.drop(columns='cluster_id'))\n",
    "### END SOLUTION\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ad7e403",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-fc50446c253e055e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "Comment in a few bullet points or sentences. How would you intepret and name each cluster?"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "76c7172c",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-a2c2c5e529ae0120",
     "locked": false,
     "points": 2,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "source": [
    "Your answer here."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72bc0c5d",
   "metadata": {
    "nbgrader": {
     "grade": false,
     "grade_id": "cell-8efdce74f123d54e",
     "locked": true,
     "schema_version": 3,
     "solution": false,
     "task": false
    }
   },
   "source": [
    "# Challenge Problem\n",
    "\n",
    "Remember, you need to do at least two of these challenge problems this quarter.\n",
    "\n",
    "This challenge problem is open ended for you to take in a direction that you are most interested in. Here are some suggestions (do 1 or 2 of these):\n",
    "* Create some dummy variables and use them to cluster. For example, the reporter type and reporting module might be useful\n",
    "* Analyze how your clusters vary by state (a field in your `transit` dataframe). For example, you might do a stacked bar chart of the number of transit agencies in each cluster by state. (Google \"pandas stacked bar\".)\n",
    "* Explore different numbers of clusters\n",
    "* Map your clusters. Your dataframe doesn't have geographic coordinates, but you could join the `Zip Code` field to [this handy dataset](https://hudgis-hud.opendata.arcgis.com/datasets/d032efff520b4bf0aa620a54a477c70e_0/about) that gives the centroids of each zip code.\n",
    "\n",
    "Write some brief interpretation in a markdown cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c7d5c47",
   "metadata": {
    "nbgrader": {
     "grade": true,
     "grade_id": "cell-01d5786b60ed43fd",
     "locked": false,
     "points": 0,
     "schema_version": 3,
     "solution": true,
     "task": false
    }
   },
   "outputs": [],
   "source": [
    "# your code here"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Create Assignment",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
