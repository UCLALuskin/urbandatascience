{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53fce03f",
   "metadata": {},
   "source": [
    "## Module 5 Class activities\n",
    "This notebook is a starting point for the exercises and activities that we'll do in class. We'll do an extension of the random forests classifier, looking at a continuous variable.\n",
    "\n",
    "Before you attempt any of these activities, make sure to watch the video lectures for this module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c092609b",
   "metadata": {},
   "source": [
    "### Classification: NYC evictions\n",
    "We'll look at the factors that are associated with evictions in New York City. Perhaps a machine learning model can identify the types of places that are vulnerable to eviction, and target renter assistance programs more effectively?\n",
    "\n",
    "#### Loading in the data\n",
    "\n",
    "Let's start by loading in the [eviction dataset](https://data.cityofnewyork.us/City-Government/Evictions/6z8x-wfk4) via Socrata."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a30faed6",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<strong>Exercise:</strong> Import the data from Socrata via the API into a pandas DataFrame.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "479b86bd",
   "metadata": {},
   "source": [
    "*Hints*:\n",
    "- Look back at Week 1 if you need a refresher on using Socrata\n",
    "- There are about 70,000 rows in the dataset. So remember to add `?$limit=100000` to the end of the URL that you pass to `requests.get()`. Otherwise, you'll just get the first 1,000 rows. (The limit can be anything comfortably above 70000.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4133f155",
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9549f5a2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "\n",
    "<strong>Exercise:</strong> Convert your dataframe to a GeoDataFrame, using the latitude and longitude columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e02f9c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc5657ee",
   "metadata": {},
   "source": [
    "Now let's import some census data. We could use `cenpy` or the Census Bureau API. But to keep things simple so that we can focus on the spatial joins and the machine learning, I downloaded the block group-level 2019 ACS data for New York from the [Census Bureau](https://www.census.gov/geographies/mapping-files/time-series/geo/tiger-data.html). To save space, I clipped it to the 5 NYC counties.\n",
    "\n",
    "It's in your repository, and we can load it in as follows. If you aren't familiar with a GeoPackage (GPKG) format, think of it as a \"new and improved shapefile.\" [Here's a good overview.](https://towardsdatascience.com/why-you-need-to-use-geopackage-files-instead-of-shapefile-or-geojson-7cb24fe56416)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "41d4aef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "bgs = gpd.read_file('data/nyc_bgs.gpkg')\n",
    "bgs.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c295e3d",
   "metadata": {},
   "source": [
    "Note that the variables aren't particularly carefully selected - I just threw in many of the demographic and housing variables. \n",
    "\n",
    "Nor are the variable names particularly informative, but the full names are in a file in the repository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "86627295",
   "metadata": {},
   "outputs": [],
   "source": [
    "# note it is tab-sepated, not comma separated\n",
    "# so we use the sep='\\t' argument\n",
    "\n",
    "col_names = pd.read_csv('data/BG_METADATA_2019.txt', sep='\\t', index_col='Short_Name')\n",
    "col_names.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e4ea2c7",
   "metadata": {},
   "source": [
    "So you can see the definition of the column like this. (I don't recommend renaming the `bg` column names, because the full names are so long.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f59fcfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "col_names.loc['B01001e1']"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1da707b5",
   "metadata": {},
   "source": [
    "#### Spatial join\n",
    "Now let's do the spatial join. Again, let's follow our three step process.\n",
    "\n",
    "1. Use a spatial join to add the `GEOID` column to the evictions dataframe. *Hint:* Check your projections.\n",
    "2. Group by `GEOID` to get a count of evictions per block group. If you have a `Series`, give it a name - maybe `n_evictions`\n",
    "3. Join those counts back - a tabular join based on the index"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "accd0b18",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <strong>Exercise:</strong> Add a count of evictions per census block group to your <strong>bgs</strong> GeoDataFrame, using the 3-step process above.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc447f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89523f4a",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> Do a quick-and-dirty map of the number of evictions. This will help identify any data holes.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2991b6f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b78b5b4f",
   "metadata": {},
   "source": [
    "#### Random forests regressor\n",
    "Now we have our data set. Let's estimate a random forests model.\n",
    "\n",
    "In contrast to the examples in the lecture, we are trying to predict a continuous variable - the number of evictions. So our classifier isn't appropriate. \n",
    "\n",
    "However, there is a similar model: the [random forest regressor](https://scikit-learn.org/stable/modules/generated/sklearn.ensemble.RandomForestRegressor.html#sklearn.ensemble.RandomForestRegressor). It works almost identically to the classifier. The main difference from a user perspective is assessing model performance - a confusion matrix doesn't work here.\n",
    "\n",
    "You'll need to follow the following steps:\n",
    "- choose your x variables. (Your y variable will be `n_evictions`)\n",
    "- Drop Null values if needed\n",
    "- split your dataset into training and testing portions\n",
    "- estimate (fit) the model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "24327cee",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> Estimate a random forest regressor model to predict the number of evictions per census tract.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "192468ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45bcc2b6-9bf0-4b15-af65-470a9ea0556e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> Examine some of your trees in the random forest. What do they tell you?</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87cb8cb1-3095-443d-a53f-daa59cf698bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83494cfc-07c2-4572-9059-5bdb9c229c15",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> Experiment with different model hyperparameters and variables. Discuss your rationale and the results with a neighbor.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "361df43e-8ac4-4394-850b-b787e5a733e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52e0ce82-4373-41fe-be47-45a3389eda6a",
   "metadata": {},
   "source": [
    "The following questions relate to some of the material in Module 6. You might want to wait until watching those lectures. Then come back and complete these tasks."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7d5483eb",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> Assess the fit of your model.</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aded99af",
   "metadata": {},
   "source": [
    "Remember, the confusion matrix and accuracy scores don't apply to continuous data. Some ideas for continuous variables are [here](https://stackoverflow.com/questions/50789508/random-forest-regression-how-do-i-analyse-its-performance-python-sklearn). You could also plot actual vs predicted values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "779701e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c1f5e2a1",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> Which variables are most important in your predictions? Plot the forest importances.</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49d83e04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2818a26",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h3>What you should have learned</h3>\n",
    "<ul>\n",
    "  <li>Get more practice with spatial joins and Socrata.</li>\n",
    "  <li>Learn how to estimate a random forests model for continuous data.</li>\n",
    "</ul>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
