{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "53fce03f",
   "metadata": {},
   "source": [
    "## Module 2 Class activities\n",
    "This notebook is a starting point for the exercises and activities that we'll do in class.\n",
    "\n",
    "Before you attempt any of these activities, make sure to watch the video lectures for this module."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c092609b",
   "metadata": {},
   "source": [
    "### Scraping permit data\n",
    "Here's the code that we saw in the video lecture that queries the City of Seattle permit website, gets a dataframe of permits (including the URL), and then digs down further into that permit-specific URL."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89222500",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the permit data from the API\n",
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "url = 'https://data.seattle.gov/resource/ht3q-kdvx.json' # copied and pasted from the webpage\n",
    "r = requests.get(url)\n",
    "df = pd.DataFrame(json.loads(r.text))\n",
    "\n",
    "df = df.head(8) # get the first 5 rows, so we don't overload the city's website.\n",
    "\n",
    "# get an example link\n",
    "permiturl = df.loc[7,'link']['url']\n",
    "print(permiturl)\n",
    "\n",
    "# request that page and get the soup object\n",
    "r = requests.get(permiturl)\n",
    "soup = BeautifulSoup(r.text)\n",
    "print(soup.prettify())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "59022053",
   "metadata": {},
   "outputs": [],
   "source": [
    "# then we wrote this code to extract the project description \n",
    "links = soup.find_all('td')\n",
    "for link in links:\n",
    "    if 'Project Description' in link.text: \n",
    "        sublinks = link.find_all('td')\n",
    "        description = sublinks[1].text\n",
    "        # once we find a description, we exit\n",
    "        break\n",
    "    \n",
    "print(description)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e6d730d",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> If you look at the example, there may be a section giving information on the number of curb cuts. Extract that to a variable and print it.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9ab6670e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hints\n",
    "# Not all of the records have the curb cut field. You can see an example here:\n",
    "# https://services.seattle.gov/portal/customize/LinkToRecord.aspx?altId=3001776-LU\n",
    "\n",
    "# If you look at that webpage, you'll see that the text \"Number of Curb Cuts for This Permit: \"\n",
    "# is within \"span\" tags\n",
    "curbcuttext = soup.find(\"span\", string=\"Number of Curb Cuts for This Permit: \")\n",
    "\n",
    "# So to get the number of curb cuts (which is the next piece of text), \n",
    "# you can ask for the NEXT tag using find_next()\n",
    "n_curbcuts = curbcuttext.find_next()\n",
    "\n",
    "# you'll need to add an if statement to deal with the case when this text does not exist\n",
    "\n",
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "041fefc9",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> Now turn that into a function that you can apply to each row of your dataframe. Add a new column, <strong>n_curbcuts</strong>, to your dataframe.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af29ac85",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e774e339",
   "metadata": {},
   "source": [
    "### Fixing errors\n",
    "We'll do more scraping in just a moment. But first, let's do some examples of how to interpret an error message, and fix it."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4cb7c600",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> Each of the cells below will generate an error. Look at the error message and see if you can figure out how to fix it. (Don't Google it until you try to figure it out based on the error message.)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dad38e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the housingunitsremoved and housingunitsadded give useful information\n",
    "# let's create a new column with netunits\n",
    "df['netunits'] = df.housingunitsadded - df.housingunitsremoved"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be7f4267",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print the address of the first row\n",
    "print('Address of first row is {}. Permit type is {}'.format(df.iloc[0].originaladdress1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1d6dfde6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert the number of housing units to integers\n",
    "# and then summarize\n",
    "\n",
    "df['unitsadded_numeric'] = df.housingunitsadded.astype(int)\n",
    "df.unitsadded_numeric.describe("
   ]
  },
  {
   "cell_type": "markdown",
   "id": "98e25862",
   "metadata": {},
   "source": [
    "### Scraping craigslist\n",
    "\n",
    "In the lecture, we saw how to scrape the main page (the list of posts).\n",
    "\n",
    "What if you want to get more information about (say) a particular apartment?\n",
    "\n",
    "Go to the [craigslist housing page](https://losangeles.craigslist.org/search/apa#search=1~gallery~0~0) and copy the link for one of the listings. It should look something like this:\n",
    "https://losangeles.craigslist.org/lgb/apa/d/long-beach-home-for-rent/7597309102.html\n",
    "\n",
    "(It's fine to copy and paste the URL for now. A second step would be to loop over the URLs from the dataframe of postings that we created in the video lecture, but in class, we'll just focus on one example.)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e3f6d0",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> For this URL, use requests to get the content of the post. (No need to create a soup object yet.)\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f8705a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "import requests\n",
    "import pandas as pd\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# your code here\n",
    "# put the output of the request in a variable called r\n",
    "# so you can access the content like this\n",
    "print(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c9e3794",
   "metadata": {},
   "source": [
    "Now let's extract more information from the page. We have a couple of strategies here. First, we could skip trying to parse the page with `BeautifulSoup`, and just see if particular bits of text are present.\n",
    "\n",
    "For example, what transportation modes does the post emphasize? Do they mention Section 8 vouchers? Some of this might be exploratoryâ€”we can see what type of language is included, and then parse in a more structured way (e.g. distinguishing between \"No Section 8\" and \"Section 8 welcome\")."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dd5bdf82",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <strong>Exercise:</strong> Write a function that will return True if Section 8 is mentioned, otherwise False."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bfb944b5",
   "metadata": {},
   "source": [
    "*Hint*: the `in` operator is a simple way to do this. For example:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad08e0cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "'plan' in 'urban planning'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "52f97024",
   "metadata": {},
   "outputs": [],
   "source": [
    "'plan' in 'Urban Planning' "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "806158ab",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here to return Section 8 information"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "707bacd1",
   "metadata": {},
   "source": [
    "Most of the post is free-form text. So there's not going to be much value added by `BeautifulSoup`.\n",
    "\n",
    "The exceptions are (i) parking, and (ii) the geographic coordinates."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "30412ae2",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <strong>Exercise:</strong> Write a function that will return True if the apartment has no parking, and also returns the lat/lon of the apartment"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3a497c9",
   "metadata": {},
   "source": [
    "*Hint*: First, create a `soup` object. Then, look and see what tag and class encloses this information. Then, you can experiment with `find` and `find_all` with this tag and class."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de7baf7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8731adec-f656-4816-9763-81366c3c0301",
   "metadata": {},
   "source": [
    "Now you've written this code, a next step would be to package it in a function that you can apply to all the URLs in your dataframe of posts (like the one we created in the video lecture). "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3bec66b-614f-4e05-81f6-af142208fbbb",
   "metadata": {},
   "source": [
    "## Large language models [Optional]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6007f461-0925-4a53-b029-6a985475bd9c",
   "metadata": {},
   "source": [
    "Large language models (LLMs) such as ChatGPT can also be accessed via an API.\n",
    "\n",
    "The APIs are changing very rapidly, as are the pricing structures. For now, some LLMs are offered for free, for limited use. One such model with a free tier is Gemini, by Google.\n",
    "\n",
    "If you'd like to experiment with Gemini, you need to [get an API key here](https://aistudio.google.com/u/1/apikey). No credit card is necessary, but your UCLA Google account won't work - you need a personal Google account.\n",
    "\n",
    "[The documentation and some examples are here](https://github.com/googleapis/python-genai).\n",
    "\n",
    "The other challenge with Gemini is that its Python library has several incompatibilities, including with some of the ones we use elsewhere in the course. So you will need to create a new environment in Anaconda, using the same setup process (importing an environment) as you did at the [start of the course](https://urbandatascience.its.ucla.edu/getting-started/).\n",
    "\n",
    "Specifically:\n",
    "- In Anaconda, go to the Environments tab\n",
    "- Click on Import\n",
    "- Choose `google-genai-env.yml` under Local Drive, and call the environment `genai`\n",
    "- Manually add the `google-genai` package (choose \"Not Installed\", type `google-genai` into the search bar, select the checkbox, and then click Apply at the bottom of the screen)\n",
    "- Anaconda will take some time, before you can click Apply again to install\n",
    "- Close this notebook and open it again after you switch to your new `genai` environment\n",
    "\n",
    "All set up? Let's look at a simple example---passing a query to the chat interface."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e0e1622-dbb2-4562-b05b-0aac7a5ab7a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from google import genai  # if this doesn't load, you probably have the wrong environment\n",
    "gemini_api_key = 'XXXX' #'XXXXX' # fill in your key here\n",
    "\n",
    "c = genai.Client(api_key=gemini_api_key)\n",
    "chat = c.chats.create(model='gemini-2.0-flash-001')\n",
    "response = chat.send_message('What do urban planners need to learn about gen AI?')\n",
    "print(response.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7016bcc3-49ad-43c4-bf15-b8c00b7bea45",
   "metadata": {},
   "source": [
    "How might this be used in web scraping? \n",
    "\n",
    "Well, perhaps you can ask it to parse the text."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e542acd7-0dc0-486e-93fd-8e0acca0d27e",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <strong>Exercise:</strong> Pass the text of the craiglist post to Gemini, and ask it to return the number of parking spaces (if any). Add the result to your dataframe. NOTE: This exercise is optional (you might not want to create a Google account to get an API key)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "730e3ed3-eb4c-4705-b01b-e30b602bb688",
   "metadata": {},
   "outputs": [],
   "source": [
    "# your code here"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a2818a26",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h3>What you should have learned</h3>\n",
    "<ul>\n",
    "  <li>Gain confidence in experimenting with code - exploring different objects, writing functions, and so on</li>\n",
    "  <li>Learn how to extract information from a scraped webpage - how to do the detective work.</li>\n",
    "  <li>Gain confidence in debugging errors.</li>\n",
    "  <li>Learn how to integrate Large Language Models into Python</li>\n",
    "</ul>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
