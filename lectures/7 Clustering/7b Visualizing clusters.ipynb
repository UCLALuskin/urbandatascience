{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "545b3a7a",
   "metadata": {},
   "source": [
    "# Visualizing clusters\n",
    "## Lecture objectives\n",
    "1. Explore how to visualize and interpret clusters\n",
    "2. Demonstrate radar plots\n",
    "3. Provide more practice with mapping\n",
    "\n",
    "Let's begin by recreating the clusters from the previous lecture."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a43ed3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn import preprocessing\n",
    "from sklearn.cluster import KMeans\n",
    "\n",
    "df = pd.read_csv('../data/c037_g20_sov_data_by_g20_srprec.csv')\n",
    "df.set_index('srprec', inplace=True)\n",
    "\n",
    "# calculate vote shares\n",
    "df['Biden_pc'] = df.PRSDEM01 / (df.PRSDEM01+df.PRSREP01)*100\n",
    "props = [col[3:5] for col in df.columns if col.startswith('PR_') and col.endswith('Y')]\n",
    "for prop in props:\n",
    "    df[prop+'_pc_yes'] = df['PR_'+prop+'_Y'] / (df['PR_'+prop+'_Y'] \n",
    "                                              + df['PR_'+prop+'_N'])*100\n",
    "for prop in ['20','22']:\n",
    "    df[prop+'_pc_no'] = 100 - df[prop+'_pc_yes']\n",
    "    df.drop(columns=[prop+'_pc_yes'], inplace=True)\n",
    "\n",
    "# choose columns\n",
    "cols_to_plot = [col for col in df.columns if '_pc' in col]\n",
    "cols_to_plot.remove('14_pc_yes') \n",
    "cols_to_plot.remove('23_pc_yes') \n",
    "cols_to_plot.remove('24_pc_yes') \n",
    "\n",
    "# standardize\n",
    "scaler = preprocessing.StandardScaler().fit(df[cols_to_plot])\n",
    "df_scaled = pd.DataFrame(scaler.transform(df[cols_to_plot]), \n",
    "                         columns=cols_to_plot, index=df.index)\n",
    "df_scaled = df_scaled.dropna()\n",
    "\n",
    "# cluster\n",
    "kmeans = KMeans(n_clusters=5, random_state=1).fit(df_scaled)\n",
    "df_scaled['cluster_id'] = kmeans.labels_\n",
    "\n",
    "# verify that we got the same result as before\n",
    "df_scaled.groupby('cluster_id').size()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3ebc3230",
   "metadata": {},
   "source": [
    "How can we best visualize what the clusters mean? If we had just two columns, a scatterplot with a color code for each cluster would work well. But we have 10 dimensions (10 columns that are used to cluster).\n",
    "\n",
    "One way is to redo our original scatter plot matrix, but with each cluster indicated."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b828f25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "ax = sns.pairplot(df_scaled, hue='cluster_id', )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63542349",
   "metadata": {},
   "source": [
    "My preferred option, however, is a radar chart. Neither `seaborn` nor `matplotlib` do this natively, but [there is an example in the `matplotlib` gallery](https://matplotlib.org/stable/gallery/specialty_plots/radar_chart.html). I've just copied and pasted that code."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cea29bc",
   "metadata": {
    "code_folding": [
     13
    ]
   },
   "outputs": [],
   "source": [
    "# code from https://matplotlib.org/stable/gallery/specialty_plots/radar_chart.html\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from matplotlib.patches import Circle, RegularPolygon\n",
    "from matplotlib.path import Path\n",
    "from matplotlib.projections.polar import PolarAxes\n",
    "from matplotlib.projections import register_projection\n",
    "from matplotlib.spines import Spine\n",
    "from matplotlib.transforms import Affine2D\n",
    "\n",
    "def radar_factory(num_vars, frame='circle'):\n",
    "    \"\"\"\n",
    "    Create a radar chart with `num_vars` axes.\n",
    "\n",
    "    This function creates a RadarAxes projection and registers it.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    num_vars : int\n",
    "        Number of variables for radar chart.\n",
    "    frame : {'circle', 'polygon'}\n",
    "        Shape of frame surrounding axes.\n",
    "\n",
    "    \"\"\"\n",
    "    # calculate evenly-spaced axis angles\n",
    "    theta = np.linspace(0, 2*np.pi, num_vars, endpoint=False)\n",
    "\n",
    "    class RadarAxes(PolarAxes):\n",
    "\n",
    "        name = 'radar'\n",
    "        # use 1 line segment to connect specified points\n",
    "        RESOLUTION = 1\n",
    "\n",
    "        def __init__(self, *args, **kwargs):\n",
    "            super().__init__(*args, **kwargs)\n",
    "            # rotate plot such that the first axis is at the top\n",
    "            self.set_theta_zero_location('N')\n",
    "\n",
    "        def fill(self, *args, closed=True, **kwargs):\n",
    "            \"\"\"Override fill so that line is closed by default\"\"\"\n",
    "            return super().fill(closed=closed, *args, **kwargs)\n",
    "\n",
    "        def plot(self, *args, **kwargs):\n",
    "            \"\"\"Override plot so that line is closed by default\"\"\"\n",
    "            lines = super().plot(*args, **kwargs)\n",
    "            for line in lines:\n",
    "                self._close_line(line)\n",
    "\n",
    "        def _close_line(self, line):\n",
    "            x, y = line.get_data()\n",
    "            # FIXME: markers at x[0], y[0] get doubled-up\n",
    "            if x[0] != x[-1]:\n",
    "                x = np.append(x, x[0])\n",
    "                y = np.append(y, y[0])\n",
    "                line.set_data(x, y)\n",
    "\n",
    "        def set_varlabels(self, labels):\n",
    "            self.set_thetagrids(np.degrees(theta), labels)\n",
    "\n",
    "        def _gen_axes_patch(self):\n",
    "            # The Axes patch must be centered at (0.5, 0.5) and of radius 0.5\n",
    "            # in axes coordinates.\n",
    "            if frame == 'circle':\n",
    "                return Circle((0.5, 0.5), 0.5)\n",
    "            elif frame == 'polygon':\n",
    "                return RegularPolygon((0.5, 0.5), num_vars,\n",
    "                                      radius=.5, edgecolor=\"k\")\n",
    "            else:\n",
    "                raise ValueError(\"Unknown value for 'frame': %s\" % frame)\n",
    "\n",
    "        def _gen_axes_spines(self):\n",
    "            if frame == 'circle':\n",
    "                return super()._gen_axes_spines()\n",
    "            elif frame == 'polygon':\n",
    "                # spine_type must be 'left'/'right'/'top'/'bottom'/'circle'.\n",
    "                spine = Spine(axes=self,\n",
    "                              spine_type='circle',\n",
    "                              path=Path.unit_regular_polygon(num_vars))\n",
    "                # unit_regular_polygon gives a polygon of radius 1 centered at\n",
    "                # (0, 0) but we want a polygon of radius 0.5 centered at (0.5,\n",
    "                # 0.5) in axes coordinates.\n",
    "                spine.set_transform(Affine2D().scale(.5).translate(.5, .5)\n",
    "                                    + self.transAxes)\n",
    "                return {'polar': spine}\n",
    "            else:\n",
    "                raise ValueError(\"Unknown value for 'frame': %s\" % frame)\n",
    "\n",
    "    register_projection(RadarAxes)\n",
    "    return theta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e9d98e9",
   "metadata": {},
   "source": [
    "I then adapted the example from the website, putting it in a function called `radar_plot` that takes two arguments:\n",
    "* the `kmeans` object\n",
    "* the dataframe with the input data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2335b403",
   "metadata": {},
   "outputs": [],
   "source": [
    "def radar_plot(kmeans, df_scaled):\n",
    "    N  = kmeans.cluster_centers_.shape[1]  # number of columns / variables\n",
    "    k = kmeans.n_clusters\n",
    "    theta = radar_factory(N, frame='polygon')\n",
    "    data = kmeans.cluster_centers_.T  # the T means transpose\n",
    "    spoke_labels = [col for col in df_scaled.columns if col!='cluster_id']\n",
    "    fig, ax = plt.subplots(figsize=(4, 4),\n",
    "                                subplot_kw=dict(projection='radar'))\n",
    "    fig.subplots_adjust(wspace=0.25, hspace=0.20, top=0.85, bottom=0.05)\n",
    "\n",
    "    ax.plot(theta, data) #, color=color)\n",
    "    ax.set_varlabels(spoke_labels)\n",
    "\n",
    "    # add legend relative to top-left plot\n",
    "    labels = ['Cluster {}'.format(kk) for kk in range(k)]\n",
    "    ax.legend(labels, loc=(0.95, .95),\n",
    "                                labelspacing=0.1, fontsize=7)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "32ce53fc",
   "metadata": {},
   "source": [
    "Let's call this function with our data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d3f1161",
   "metadata": {},
   "outputs": [],
   "source": [
    "radar_plot(kmeans, df_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa51aebe-edb4-4966-a33a-054586e54cc5",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "    <strong>Exercise:</strong> Add the size of each cluster to the legend. <em>Hint</em>: Look at the second to last line that defines the labels. And remember that you can group by <strong>cluster_id</strong> to get the cluster sizes.\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81fb8699-0e6f-4f0a-ae1e-8e6fef18e4cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get the cluster sizes as we did before\n",
    "csizes = df_scaled.groupby('cluster_id').size()\n",
    "# then insert that into the string\n",
    "# you'd change this in the function above, not here\n",
    "k = kmeans.n_clusters\n",
    "labels = ['Cluster {} (N={})'.format(kk, csizes.loc[kk]) for kk in range(k)]\n",
    "labels"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6bf59e99",
   "metadata": {},
   "source": [
    "### Exploring different numbers of clusters\n",
    "Here, the interesting finding is that all the clusters form concentric circles. There isn't a cluster of precincts that (say) votes against rent control but is progressive on the other items on the ballot.\n",
    "\n",
    "We can certainly find these clusters if we increase `k`, but then these \"weird\" clusters have few precincts.\n",
    "\n",
    "For example, let's try with `k=10`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8840f2af",
   "metadata": {},
   "outputs": [],
   "source": [
    "# drop the old cluster id, so that we don't include it in our new estimates\n",
    "df_scaled.drop(columns=['cluster_id'], inplace=True)  \n",
    "\n",
    "# this is the same code as before\n",
    "kmeans = KMeans(n_clusters=10, random_state=1).fit(df_scaled)\n",
    "df_scaled['cluster_id'] = kmeans.labels_\n",
    "print(df_scaled.groupby('cluster_id').size())\n",
    "radar_plot(kmeans, df_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21c048d1",
   "metadata": {},
   "source": [
    "Let's go back to our original 5 clusters."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "617d3db6",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_scaled.drop(columns=['cluster_id'], inplace=True) \n",
    "kmeans = KMeans(n_clusters=5, random_state=1).fit(df_scaled)\n",
    "df_scaled['cluster_id'] = kmeans.labels_\n",
    "radar_plot(kmeans, df_scaled)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f88b76fc",
   "metadata": {},
   "source": [
    "### Mapping the clusters\n",
    "The Statewide Database team provide geographic boundary files as well as the vote counts. The shapefile for Los Angeles count is in your GitHub respository."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "530bbbec",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "\n",
    "gdf = gpd.read_file('../data/srprec_037_g20_v01_shp/srprec_037_g20_v01.shp')\n",
    "gdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb926639",
   "metadata": {},
   "source": [
    "Note that there is no projection file, so geopandas doesn't know the coordinate system."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a441135",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(gdf.crs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e2227f92",
   "metadata": {},
   "source": [
    "The documentation online says it's in lat/lon, so let's set it to EPSG 4326."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68d4505f",
   "metadata": {},
   "outputs": [],
   "source": [
    "gdf.crs = 'EPSG:4326'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdfa165e",
   "metadata": {},
   "source": [
    "Before we do a join, let's look at the data to figure out the number of rows and the join column, and whether `srprec` is a unique identifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a6d1fc",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# looks like we can join on srprec, \n",
    "# but we'll need to set that as the index for gdf\n",
    "from IPython.display import display\n",
    "display(df_scaled.head())\n",
    "display(gdf.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c077aaad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# we have more observations in our spatial data, so we can do a left join to that\n",
    "# maybe some precincts have no voters?\n",
    "print(len(gdf))\n",
    "print(len(df_scaled))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "04733a09",
   "metadata": {},
   "outputs": [],
   "source": [
    "# both are unique, which makes things easier\n",
    "print(df_scaled.index.is_unique)\n",
    "print(gdf.SRPREC.is_unique)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e41220f2",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# do the join\n",
    "gdf.set_index('SRPREC', inplace=True)\n",
    "joinedGdf = gdf.join(df_scaled)\n",
    "joinedGdf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eaa373e5",
   "metadata": {},
   "source": [
    "Let's map the clusters. We should color code by `cluster_id`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d9a8353",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "import contextily as ctx\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "\n",
    "joinedGdf.to_crs('EPSG:3857').plot('cluster_id', legend=True, ax = ax, alpha=0.4)\n",
    "ctx.add_basemap(ax, zoom=12, source=ctx.providers.OpenStreetMap.Mapnik)\n",
    "\n",
    "# drop Catalina Island\n",
    "ax.set_ylim([3.98e6, 4.14e6])\n",
    "\n",
    "# and we really don't need the axis ticks and labels, so we set them to an empty list\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])\n",
    "\n",
    "ax.set_title('Typology of voting, 2020 General Election', fontsize=10)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f2848cd",
   "metadata": {},
   "source": [
    "What can we do to improve the map?\n",
    "\n",
    "The `source` keyword gives access to lots of options. Take a look at the possibilities with `ctx.providers`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2637da4",
   "metadata": {},
   "outputs": [],
   "source": [
    "ctx.providers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7a84482",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<strong>Exercise:</strong> How else would you improve the map?\n",
    "</div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "482adcf2",
   "metadata": {},
   "source": [
    "There's no right answer here, but I first replace the missing data with an explicit \"no data\" label. To do that, we need to change the data type of `cluster_id` to string.\n",
    "\n",
    "We can also remove the decimal point from the other cluster labels using the `str.replace()` function. We replace `.0` with an empty string."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8e5acf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "joinedGdf.cluster_id = joinedGdf.cluster_id.astype(str)\n",
    "joinedGdf.cluster_id = joinedGdf.cluster_id.str.replace('.0', '')\n",
    "joinedGdf.cluster_id = joinedGdf.cluster_id.str.replace('nan', 'No data')\n",
    "\n",
    "joinedGdf.cluster_id.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79c98ba1",
   "metadata": {},
   "source": [
    "In the plot itself, we might:\n",
    "* replace the colorbar with a legend. This is because we have discrete categories (0-5), not a continuous variable. That is done with the `categorical=True` keyword argument.\n",
    "* add a legend title. We get the legend and then use the `set_title()` function.\n",
    "* specify the colors. I find https://colorbrewer2.org the most helpful. \n",
    "* specify a gray for missing data (a grayscale color is a string between 0 and 1. E.g. 0 is black and 1 is white, with values in between representing progressively lighter shades."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64a34df4",
   "metadata": {
    "code_folding": []
   },
   "outputs": [],
   "source": [
    "# getting the colors into a colormap required some searching\n",
    "# https://stackoverflow.com/questions/38882233/geopandas-matplotlib-plot-custom-colors\n",
    "from matplotlib.colors import LinearSegmentedColormap\n",
    "cmap = LinearSegmentedColormap.from_list(\n",
    "    'mycmap', [(0, '#7fc97f'), (0.2, '#beaed4'), (0.4, '#fdc086'), \n",
    "               (0.6, '#ffff99'), (0.8, '#386cb0'), (1.0, '0.5')])\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(5,5))\n",
    "joinedGdf.to_crs('EPSG:3857').plot('cluster_id', ax=ax, categorical=True, \n",
    "                                  legend=True, alpha=0.4, cmap=cmap,\n",
    "                                  legend_kwds={'loc': 'upper left'})\n",
    "\n",
    "# add a legend title\n",
    "legend = ax.get_legend()\n",
    "legend.set_title(\"Cluster\", prop={'size':10} )\n",
    "\n",
    "# all this is the same as before\n",
    "ctx.add_basemap(ax, zoom=12, source=ctx.providers.OpenStreetMap.Mapnik)\n",
    "ax.set_title('Typology of voting, 2020 General Election', fontsize=10)                           \n",
    "ax.set_ylim([3.98e6, 4.14e6])\n",
    "ax.set_xticks([])\n",
    "ax.set_yticks([])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "129f0226",
   "metadata": {},
   "source": [
    "<div class=\"alert alert-block alert-info\">\n",
    "<h3>Key Takeaways</h3>\n",
    "<ul>\n",
    "  <li>Even if the clusters are pretty self-explanatory, they can be useful</li>\n",
    "  <li>Radar plots and maps are two useful visualizations that help you interpret your clusters.\n",
    "  <li>They can be a starting point for further quantitative researchâ€”perhaps, use them as a variable in a regression model</li>\n",
    "  <li>They can also be useful for qualitative research. Perhaps you might do a case study of each cluster, picking the precinct/city/agency that is closest to each cluster center</li>\n",
    "</ul>\n",
    "</div>"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.11"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
